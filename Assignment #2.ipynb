{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Question 1***\n",
      "Wrote 10000 lines.\n",
      "\n",
      "***Question 2***\n",
      "Out of sample (RMSE): 261.55503023152124\n",
      "\n",
      "***Question 3***\n",
      "length:(5.4895,2.8474024162474727)\n",
      "width:(5.4783,2.8547055968006094)\n",
      "height:(5.52,2.872981970451614)\n",
      "     height    length     width\n",
      "0 -0.877137 -1.576700 -1.218444\n",
      "1 -0.180997 -0.874306 -1.218444\n",
      "2 -0.877137 -0.523108 -1.568743\n",
      "\n",
      "***Question 4***\n",
      "Fold #1\n",
      "Fold score (RMSE): 0.20131494355764176\n",
      "Fold #2\n",
      "Fold score (RMSE): 0.15472213077299496\n",
      "Fold #3\n",
      "Fold score (RMSE): 0.1806365862097857\n",
      "Fold #4\n",
      "Fold score (RMSE): 0.21541695913948652\n",
      "Fold #5\n",
      "Fold score (RMSE): 0.20215257929374797\n",
      "Final, out of sample score (RMSE): 0.19202414021580508\n",
      "\n",
      "***Question 5***\n",
      "Fold #1\n",
      "Fold score: 0.8625\n",
      "Fold #2\n",
      "Fold score: 0.55\n",
      "Fold #3\n",
      "Fold score: 0.5\n",
      "Fold #4\n",
      "Fold score: 0.46835443037974683\n",
      "Fold #5\n",
      "Fold score: 0.8987341772151899\n",
      "Final, out of sample score: 0.6557788944723618\n"
     ]
    }
   ],
   "source": [
    "# Programming Assignment #2 \n",
    "# Hanyu Feng \n",
    "# Student ID:452106\n",
    "# T81-558: Application of Deep Learning\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#from sklearn.model_selection import KFold\n",
    "import shutil\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "# These four functions will help you, they were covered in class.\n",
    "# Encode a text field to dummy variables\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode a text field to a single index value\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric field to Z-Scores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "# Encode a numeric field to fill missing values with the median.\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert a dataframe to x/y suitable for training.\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    return df.as_matrix(result),df[target]\n",
    "\n",
    "#encode_toy_dataset definition\n",
    "def encode_toy_dataset(df):\n",
    "    encode_numeric_zscore(df,'height')\n",
    "    encode_numeric_zscore(df,'width')\n",
    "    encode_numeric_zscore(df,'length')\n",
    "    encode_text_dummy(df,'shape')\n",
    "    encode_text_dummy(df,'metal')\n",
    "    return df\n",
    "\n",
    "def get_model_dir(name,erase):\n",
    "    base_path = os.path.join(\".\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    if erase and len(model_dir)>4 and os.path.isdir(model_dir):\n",
    "        shutil.rmtree(model_dir,ignore_errors=True) # be careful, this deletes everything below the specified path\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "# Encode the toy dataset\n",
    "def question1():\n",
    "    print()\n",
    "    print(\"***Question 1***\")\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    filename_read = os.path.join(path,\"toy1.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-hanyu-prog2q1.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    df = encode_toy_dataset(df)\n",
    "    df.to_csv(filename_write,index=False)\n",
    "    print(\"Wrote {} lines.\".format(len(df)))\n",
    "\n",
    "\n",
    "# Model the toy dataset, no cross validation\n",
    "def question2():\n",
    "    print()\n",
    "    print(\"***Question 2***\")\n",
    "    \n",
    " \n",
    "    filename_read = os.path.join(path,\"submit-hanyu-prog2q1.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    \n",
    "    #shuffle the data\n",
    "    np.random.seed(42)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Encode to a 2D matrix for training\n",
    "    x,y = to_xy(df,'weight')\n",
    "    \n",
    "    #Split into train/test \n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Get/clear a directory to store the neural network to\n",
    "    model_dir = get_model_dir('weight',True)\n",
    "    \n",
    "    # Create a deep neural network with 3 hidden layers of 50, 25, 10\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "    regressor = skflow.DNNRegressor(\n",
    "    model_dir= model_dir,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[50, 25, 10])\n",
    "    \n",
    "    # Early stopping\n",
    "    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=50,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "    # Fit/train neural network\n",
    "    regressor.fit(x_train, y_train,monitors=[validation_monitor],steps=1000)\n",
    "\n",
    "    # Measure RMSE error.  RMSE is common for regression.\n",
    "    pred = list(regressor.predict(x_test, as_iterable=True))\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Out of sample (RMSE): {}\".format(score))\n",
    "\n",
    "def question3():\n",
    "    print()\n",
    "    print(\"***Question 3***\")\n",
    "    \n",
    "    filename_read = os.path.join(path,\"toy1.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-hanyu-prog2q3.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    lmean = df['length'].mean()\n",
    "    lstdv = df['length'].std()\n",
    "    print(\"length:({},{})\".format(lmean,lstdv))\n",
    "    wmean = df['width'].mean()\n",
    "    wstdv = df['width'].std()\n",
    "    print(\"width:({},{})\".format(wmean,wstdv))\n",
    "    hmean = df['height'].mean()\n",
    "    hstdv = df['height'].std()\n",
    "    print(\"height:({},{})\".format(hmean,hstdv))\n",
    "    \n",
    "    # Z-Score encode these using the mean/sd from the dataset (you got this in question 2)\n",
    "    testDF = pd.DataFrame([\n",
    "            {'length':1, 'width':2, 'height': 3},\n",
    "            {'length':3, 'width':2, 'height': 5},\n",
    "            {'length':4, 'width':1, 'height': 3}\n",
    "        ])\n",
    "    \n",
    "    testDF['height'] = (testDF['height'] - hmean)/hstdv\n",
    "    testDF['length'] = (testDF['length'] - lmean)/lstdv\n",
    "    testDF['width'] = (testDF['width'] - wmean)/wstdv\n",
    "    print(testDF)\n",
    "    testDF.to_csv(filename_write,index=False)\n",
    "\n",
    "def question4():\n",
    "    print()\n",
    "    print(\"***Question 4***\")\n",
    "    filename_read = os.path.join(path,\"iris.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-hanyu-prog2q4.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    \n",
    "    encode_numeric_zscore(df,'sepal_l')\n",
    "    encode_numeric_zscore(df,'sepal_w')\n",
    "    encode_numeric_zscore(df,'petal_l')\n",
    "    encode_text_dummy(df,'species')\n",
    "    \n",
    "    #shuffle the data\n",
    "    np.random.seed(42)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Encode to a 2D matrix for training\n",
    "    x,y=to_xy(df,'petal_w')\n",
    "    \n",
    "    # Cross validate\n",
    "    kf = KFold(len(df), n_folds=5)\n",
    "\n",
    "    oos_y = []\n",
    "    oos_pred = []\n",
    "    fold = 0\n",
    "    for train, test in kf:\n",
    "        fold+=1\n",
    "        print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "    \n",
    "        # Get/clear a directory to store the neural network to\n",
    "        model_dir = get_model_dir('petal_w-{}'.format(fold),True) # Each fold has its own folder\n",
    "\n",
    "        # Create a deep neural network with 3 hidden layers of 50, 25, 10\n",
    "        feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "        regressor = skflow.DNNRegressor(\n",
    "            model_dir= model_dir,\n",
    "            config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "            feature_columns=feature_columns,\n",
    "            hidden_units=[50, 25, 10])\n",
    "\n",
    "        # Early stopping\n",
    "        validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "            x_test,\n",
    "            y_test,\n",
    "            every_n_steps=500,\n",
    "            early_stopping_metric=\"loss\",\n",
    "            early_stopping_metric_minimize=True,\n",
    "            early_stopping_rounds=50)\n",
    "    \n",
    "        # Fit/train neural network\n",
    "        regressor.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "\n",
    "        # Add the predictions to the oos prediction list\n",
    "        pred = list(regressor.predict(x_test, as_iterable=True))\n",
    "    \n",
    "        oos_y.append(y_test)\n",
    "        oos_pred.append(pred)        \n",
    "\n",
    "        # Measure accuracy\n",
    "        score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "        print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "    #Build the oos prediction list and calculate the error.\n",
    "    oos_y = np.concatenate(oos_y)\n",
    "    oos_pred = np.concatenate(oos_pred)\n",
    "    score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "    print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "    \n",
    "    oos_y = pd.DataFrame(oos_y)\n",
    "    oos_pred = pd.DataFrame(oos_pred)\n",
    "    oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "    oosDF.to_csv(filename_write,index=False)\n",
    "    \n",
    "    \n",
    "def question5():\n",
    "    print()\n",
    "    print(\"***Question 5***\")\n",
    "    \n",
    "    filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-hanyu-prog2q5.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    \n",
    "    med = df['horsepower'].median()\n",
    "    df['horsepower'] = df['horsepower'].fillna(med) \n",
    "    encode_numeric_zscore(df, 'mpg')\n",
    "    encode_numeric_zscore(df, 'horsepower')\n",
    "    encode_numeric_zscore(df, 'weight')\n",
    "    encode_numeric_zscore(df, 'displacement')\n",
    "    encode_numeric_zscore(df, 'acceleration')\n",
    "    encode_numeric_zscore(df, 'origin')\n",
    "    temp = df['name']\n",
    "    df.drop('name',1,inplace=True)\n",
    "    cylinders = encode_text_index(df,\"cylinders\")\n",
    "    num_classes = len(cylinders)\n",
    "    \n",
    "    # Shuffle\n",
    "    np.random.seed(42)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Encode to a 2D matrix for training\n",
    "    x,y = to_xy(df,'cylinders')\n",
    "    \n",
    "    # Cross validate\n",
    "    kf = KFold(len(df), n_folds=5)\n",
    "\n",
    "    oos_y = []\n",
    "    oos_pred = []\n",
    "    fold = 0\n",
    "    for train, test in kf:\n",
    "        fold+=1\n",
    "        print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "    \n",
    "        # Get/clear a directory to store the neural network to\n",
    "        model_dir = get_model_dir('cylinders-{}'.format(fold),True) # Each fold has its own folder\n",
    "\n",
    "        # Create a deep neural network with 3 hidden layers of 10, 20, 5\n",
    "        feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "        classifier = skflow.DNNClassifier(\n",
    "        model_dir= model_dir,\n",
    "        hidden_units=[10, 20, 5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "        # Early stopping\n",
    "        validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        every_n_steps=50,\n",
    "        early_stopping_metric=\"loss\",\n",
    "        early_stopping_metric_minimize=True,\n",
    "        early_stopping_rounds=250)\n",
    "    \n",
    "        # Fit/train neural network\n",
    "        classifier.fit(x_train, y_train,monitors=[validation_monitor],steps=500)\n",
    "\n",
    "        # Add the predictions to the oos prediction list\n",
    "        pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "    \n",
    "        oos_y.append(y_test)\n",
    "        oos_pred.append(pred)        \n",
    "\n",
    "        # Measure accuracy\n",
    "        score = metrics.accuracy_score(y_test, pred)\n",
    "        print(\"Fold score: {}\".format(score))\n",
    "\n",
    "\n",
    "    #Build the oos prediction list and calculate the error.\n",
    "    oos_y = np.concatenate(oos_y)\n",
    "    oos_pred = np.concatenate(oos_pred)\n",
    "    score = metrics.accuracy_score(oos_y, oos_pred)\n",
    "    print(\"Final, out of sample score: {}\".format(score)) \n",
    "      \n",
    "    # Write the cross-validated prediction\n",
    "    oos_y = pd.DataFrame(oos_y)\n",
    "    oos_pred = pd.DataFrame(oos_pred)\n",
    "    oos_y.columns = ['ideal']\n",
    "    oos_pred.columns = ['predict']\n",
    "    oosDF = pd.concat( [df, temp, oos_y, oos_pred],axis=1 )\n",
    "    oosDF.to_csv(filename_write,index=False)\n",
    "    \n",
    "\n",
    "question1()\n",
    "question2()\n",
    "question3()\n",
    "question4()\n",
    "question5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}