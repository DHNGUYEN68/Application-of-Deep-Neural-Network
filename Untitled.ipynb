{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Question 1***\n",
      "Wrote 10000 lines.\n",
      "\n",
      "***Question 2***\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1ff95372bc20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0mquestion1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m \u001b[0mquestion2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0mquestion3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0mquestion4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1ff95372bc20>\u001b[0m in \u001b[0;36mquestion2\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Create a deep neural network with 3 hidden layers of 10, 20, 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     regressor = skflow.DNNClassifier(hidden_units=[10, 20, 10], n_classes=num_classes,\n\u001b[0;32m--> 110\u001b[0;31m         steps=10000)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'steps'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "path = \"./data/\"\n",
    "# These four functions will help you, they were covered in class.\n",
    "# Encode a text field to dummy variables\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "# Encode a text field to a single index value\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "\n",
    "# Encode a numeric field to Z-Scores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "    \n",
    "    \n",
    "    \n",
    "# Encode a numeric field to fill missing values with the median.\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "# Convert a dataframe to x/y suitable for training.\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    return df.as_matrix(result),df[target]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encode the toy dataset\n",
    "def question1():\n",
    "    print()\n",
    "    print(\"***Question 1***\")\n",
    "    path = \"./data/\"\n",
    "    \n",
    "    filename_read = os.path.join(path,\"toy1.csv\")\n",
    "    \n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    filename_write = os.path.join(path,\"submit-hanmingli-prog2q1.csv\")\n",
    "\n",
    "    \n",
    "    df['height'] = zscore(df['height'])\n",
    "    df['width'] = zscore(df['width'])\n",
    "    encode_numeric_zscore(df,'length')\n",
    "\n",
    "    encode_text_dummy(df,'metal')\n",
    "    encode_text_dummy(df,'shape')\n",
    "    \n",
    "    df.to_csv(filename_write,index=False)\n",
    "    \n",
    "    \n",
    "    print(\"Wrote {} lines.\".format(len(df)))\n",
    "    \n",
    "def question2():\n",
    "    print()\n",
    "    print(\"***Question 2***\")\n",
    "    \n",
    "    \n",
    "    path = \"./data/\"\n",
    "\n",
    "    # Read dataset\n",
    "    filename_read = os.path.join(path,\"submit-hanmingli-prog2q1.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "    weight = encode_text_index(df,\"weight\")\n",
    "    # Create x(predictors) and y (expected outcome)\n",
    "    x,y = to_xy(df,'weight')\n",
    "\n",
    "\n",
    "    num_classes = len(weight)\n",
    "\n",
    "\n",
    "    # Split into train/test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(    \n",
    "        x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "    # Create a deep neural network with 3 hidden layers of 10, 20, 10\n",
    "    regressor = skflow.TenserFlowDNNClassifier(hidden_units=[10, 20, 10], n_classes=num_classes,\n",
    "        steps=10000)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stop = skflow.monitors.ValidationMonitor(x_test, y_test,\n",
    "        early_stopping_rounds=10000, print_steps=100, n_classes=num_classes)\n",
    "\n",
    "    # Fit/train neural network\n",
    "    regressor.fit(x_train, y_train, monitor=early_stop)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Measure accuracy\n",
    "    pred = regressor.predict(x_test)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def question3():\n",
    "    print()\n",
    "    print(\"***Question 3***\")\n",
    "    \n",
    "    \n",
    "    path = \"./data/\"\n",
    "    \n",
    "    filename_read = os.path.join(path,\"toy1.csv\")\n",
    "    \n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    filename_write = os.path.join(path,\"submit-hanmingli-prog2q3.csv\")\n",
    "    \n",
    "    length_mean=df['length'].mean()\n",
    "    width_mean=df['width'].mean()\n",
    "    height_mean=df['height'].mean()\n",
    "    \n",
    "    length_std=df['length'].std()\n",
    "    width_std=df['width'].std()\n",
    "    height_std=df['height'].std()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"length: ({}, {})\".format(length_mean,length_std))\n",
    "    print(\"width:({}, {})\".format(width_mean,width_std))\n",
    "    print(\"height:({}, {})\".format(height_mean,height_std))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Z-Score encode these using the mean/sd from the dataset (you got ‚Üê  this in question 2)\n",
    "    testDF = pd.DataFrame([\n",
    "            {'length':1, 'width':2, 'height': 3},\n",
    "            {'length':3, 'width':2, 'height': 5},\n",
    "            {'length':4, 'width':1, 'height': 3}\n",
    "         ])\n",
    "    \n",
    "    encode_numeric_zscore(testDF,'length',mean=length_mean,sd=length_std)\n",
    "    encode_numeric_zscore(testDF,'width',mean=width_mean,sd=width_std)\n",
    "    encode_numeric_zscore(testDF,'height',mean=height_mean,sd=height_std)\n",
    "    \n",
    "    print(testDF)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    testDF.to_csv(filename_write,index=False)    \n",
    "def question4():\n",
    "    print()\n",
    "    print(\"***Question 4***\")\n",
    "    \n",
    "    path = \"./data/\"\n",
    "\n",
    "    filename_read = os.path.join(path,\"iris.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-hanmingli-prog2q4.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "    name = ['species', 'sepal_l', 'sepal_w',  'petal_l','petal_w']\n",
    "    df = pd.DataFrame(df[name])\n",
    "    \n",
    "    encode_numeric_zscore(df,'petal_l')\n",
    "    encode_numeric_zscore(df,'sepal_w')\n",
    "    encode_numeric_zscore(df,'sepal_l')\n",
    "    encode_text_dummy(df,\"species\")\n",
    "    np.random.seed(42)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    x, y = to_xy(df,'petal_w')\n",
    "\n",
    "    # Cross validate\n",
    "    kf = KFold(len(x), n_folds=5)\n",
    "\n",
    "    oos_y = []\n",
    "    oos_pred = []\n",
    "    oos_x = []\n",
    "    fold = 1\n",
    "    for train, test in kf:        \n",
    "        print(\"Fold #{}\".format(fold))\n",
    "        fold+=1\n",
    "\n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "\n",
    "        # Create a deep neural network with 3 hidden layers of 10, 20, 10\n",
    "        regressor = skflow.TensorFlowDNNRegressor(hidden_units=[10, 20, 10], steps=500)\n",
    "\n",
    "        # Early stopping\n",
    "        early_stop = skflow.monitors.ValidationMonitor(x_test, y_test,\n",
    "            early_stopping_rounds=200, print_steps=50)\n",
    "\n",
    "        # Fit/train neural network\n",
    "        regressor.fit(x_train, y_train, monitor=early_stop)\n",
    "\n",
    "        # Add the predictions to the oos prediction list\n",
    "        pred = regressor.predict(x_test)\n",
    "\n",
    "        oos_y.append(y_test)\n",
    "        oos_pred.append(pred)  \n",
    "        oos_x.append(x_test)\n",
    "\n",
    "        # Measure accuracy\n",
    "        score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "        print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "    # Build the oos prediction list and calculate the error.\n",
    "    oos_y = np.concatenate(oos_y)\n",
    "    oos_pred = np.concatenate(oos_pred)\n",
    "    oos_x = np.concatenate(oos_x)\n",
    "   \n",
    "    score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "    print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "    # Write the cross-validated prediction\n",
    "    oos_y = pd.DataFrame(oos_y)\n",
    "    oos_pred = pd.DataFrame(oos_pred)\n",
    "    oos_x = pd.DataFrame(oos_x)\n",
    "    oos_x.insert(3,'petal_w',oos_y[:])\n",
    "    oosDF = pd.concat([oos_x,oos_y, oos_pred],axis=1 )\n",
    "    oosDF.columns = ['sepal_l','sepal_w','petal_l','petal_w','species-Iris-setosa','species-Iris-versicolor','species-Iris-virginica',0,0]\n",
    "    oosDF.to_csv(filename_write,index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "def question5():\n",
    "    print()\n",
    "    print(\"***Question 5***\")\n",
    "    filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "    filename_write = os.path.join(path,\"submit-hanmingli-prog2q5.csv\")\n",
    "    df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "    # create feature vector\n",
    "    missing_median(df, 'horsepower')\n",
    "    encode_numeric_zscore(df, 'mpg')\n",
    "    encode_numeric_zscore(df, 'horsepower')\n",
    "    encode_numeric_zscore(df, 'weight')\n",
    "    encode_numeric_zscore(df, 'displacement')\n",
    "    encode_numeric_zscore(df, 'acceleration')\n",
    "    encode_numeric_zscore(df, 'origin')\n",
    "    \n",
    "    \n",
    "    tem=df['name']\n",
    "    df.drop('name',1,inplace=True)\n",
    "    \n",
    "    \n",
    "    # Shuffle\n",
    "    np.random.seed(42)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Encode to a 2D matrix for training\n",
    "    x,y = to_xy(df,'cylinders')\n",
    "\n",
    "    # Cross validate\n",
    "    kf = KFold(len(x), n_folds=5)\n",
    "    \n",
    "    oos_y = []\n",
    "    oos_pred = []\n",
    "    fold = 1\n",
    "    for train, test in kf:        \n",
    "        print(\"Fold #{}\".format(fold))\n",
    "        fold+=1\n",
    "        \n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "        \n",
    "       \n",
    "        # Create a deep neural network with 3 hidden layers of 10, 20, 10\n",
    "        classifier = skflow.TensorFlowDNNClassifier(hidden_units=[10, 20, 10], n_classes=9,\n",
    "            steps=500)\n",
    "\n",
    "        # Early stopping\n",
    "        early_stop = skflow.monitors.ValidationMonitor(x_test, y_test,\n",
    "            early_stopping_rounds=200, print_steps=50, n_classes=9)\n",
    "    \n",
    "        # Fit/train neural network\n",
    "        classifier.fit(x_train, y_train, monitor=early_stop)\n",
    "        \n",
    "        # Add the predictions to the oos prediction list\n",
    "        pred = classifier.predict(x_test)\n",
    "    \n",
    "        oos_y.append(y_test)\n",
    "        oos_pred.append(pred)        \n",
    "\n",
    "        # Measure accuracy\n",
    "        score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "        print(\"Fold score: {}\".format(score))\n",
    "\n",
    "\n",
    "    # Build the oos prediction list and calculate the error.\n",
    "    oos_y = np.concatenate(oos_y)\n",
    "    oos_pred = np.concatenate(oos_pred)\n",
    "    score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "    print(\"Final, out of sample score: {}\".format(score))    \n",
    "    \n",
    "    # Write the cross-validated prediction\n",
    "    oos_y = pd.DataFrame(oos_y)\n",
    "    oos_pred = pd.DataFrame(oos_pred)\n",
    "    oos_y.columns = ['ideal']\n",
    "    oos_pred.columns = ['predict']\n",
    "    oosDF = pd.concat( [df, tem,oos_y, oos_pred],axis=1 )\n",
    "    oosDF.to_csv(filename_write,index=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "question1()\n",
    "question2()\n",
    "question3()\n",
    "question4()\n",
    "question5()        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
