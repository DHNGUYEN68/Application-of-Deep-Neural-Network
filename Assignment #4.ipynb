{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyufeng/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Programming Assignment #4\n",
    "# Hanyu Feng \n",
    "# Student ID:452106\n",
    "# T81-558: Application of Deep Learning\n",
    "\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.contrib.learn as learn\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "#from sklearn.model_selection import KFold\n",
    "import shutil\n",
    "import time\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "path = \"./assignment4\"\n",
    "\n",
    "# Encode a text field to dummy variables\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode a text field to a single index value\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric field to Z-Scores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    if sd ==0:\n",
    "        df[name] = df[name]\n",
    "    else :\n",
    "        df[name] = (df[name]-mean)/sd\n",
    "    \n",
    "\n",
    "\n",
    "# Encode a numeric field to fill missing values with the median.\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert a dataframe to x/y suitable for training.\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    return df.as_matrix(result),df[target]\n",
    "\n",
    "\n",
    "\n",
    "def get_model_dir(name,erase):\n",
    "    base_path = os.path.join(\"./final project\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    if erase and len(model_dir)>4 and os.path.isdir(model_dir):\n",
    "        shutil.rmtree(model_dir,ignore_errors=True) # be careful, this deletes everything below the specified path\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Assignment4***\n",
      "Elapsed time: 0:00:16.07\n",
      "Best step: 500, Last successful step: 1000\n",
      "Final accuracy: 0.7701149425287356\n",
      "Log loss score: 7.940068076606968\n"
     ]
    }
   ],
   "source": [
    "print(\"***Assignment4***\")\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# Use the data to predict which set should the data be\n",
    "# This is a Classification problem\n",
    "#   https://archive.ics.uci.edu/ml/datasets/Liver+Disorders\n",
    "\n",
    "# Read the data\n",
    "# Liver disorder data set is selected\n",
    "filename = os.path.join(path,\"bupa.csv\")\n",
    "df = pd.read_csv(filename,na_values=['NA','?'])\n",
    "\n",
    "# The first 5 variables are all blood tests which are thought to be sensitive to liver disorders that might arise from excessive alcohol consumption. \n",
    "# Each line in the bupa.data file constitutes the record of a single male individual. \n",
    "# It appears that drinks>5 is some sort of a selector on this database. \n",
    "# See the PC/BEAGLE User's Guide for more information.\n",
    "\n",
    "# 1. mcv mean corpuscular volume \n",
    "# 2. alkphos alkaline phosphotase \n",
    "# 3. sgpt alamine aminotransferase \n",
    "# 4. sgot aspartate aminotransferase \n",
    "# 5. gammagt gamma-glutamyl transpeptidase \n",
    "# 6. drinks number of half-pint equivalents of alcoholic beverages drunk per day \n",
    "# 7. selector field used to split data into two sets\n",
    "\n",
    "# Preprocess the data\n",
    "\n",
    "missing_median(df,'mcv')\n",
    "encode_numeric_zscore(df,'mcv')\n",
    "missing_median(df,'alkphos')\n",
    "encode_numeric_zscore(df,'alkphos')\n",
    "missing_median(df,'sgpt')\n",
    "encode_numeric_zscore(df,'sgpt')\n",
    "missing_median(df,'sgot')\n",
    "encode_numeric_zscore(df,'sgot')\n",
    "missing_median(df,'gammagt')\n",
    "encode_numeric_zscore(df,'gammagt')\n",
    "missing_median(df,'drinks')\n",
    "encode_numeric_zscore(df,'drinks')\n",
    "#encode_text_index(df,'selector')\n",
    "\n",
    "classnum = encode_text_index(df,'selector')\n",
    "num_classes = len(classnum)\n",
    "\n",
    "# Split the data\n",
    "x,y = to_xy(df,'selector')\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "x, y, test_size=0.25,random_state = 45)\n",
    "\n",
    "# Get/clear a directory to store the neural network to\n",
    "model_dir = get_model_dir('bupa',True)\n",
    "\n",
    "# Choose an optimizer\n",
    "#opt=tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "\n",
    "# Create a deep neural network with 3 hidden layers of 10,20,5\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir, \n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "    hidden_units=[10,20,5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "\n",
    "\n",
    "# Early stopping\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit/train neural network\n",
    "classifier.fit(x_train, y_train, monitors=[validation_monitor],steps=10000)\n",
    "\n",
    "# Calculate the time used for trainning\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))\n",
    "\n",
    "# Output the best step\n",
    "print(\"Best step: {}, Last successful step: {}\".format(\n",
    "validation_monitor.best_step,validation_monitor._last_successful_step))\n",
    "\n",
    "# Don't display numpy in scientific notation\n",
    "pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"Final accuracy: {}\".format(score))\n",
    "\n",
    "# Display the Log-Loss\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}