{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Class 12: Deep Learning Applications**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tonight we will see how to apply deep learning networks to data science.  There are many applications of deep learning.  However, we will focus primarily upon data science.  For this class we will go beyond simple academic examples and see how to construct an ensemble that could potentially lead to a high score on a Kaggle competition.  We will see how to evaluate the importance of features and several ways to combine models.\n",
    "\n",
    "Tonights topics include:\n",
    "\n",
    "* Log Loss Error\n",
    "* Evaluating Feature Importance\n",
    "* The Biological Response Data Set\n",
    "* Neural Network Bagging\n",
    "* Nueral Network Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions from Previous Classes\n",
    "\n",
    "The following are utility functions from previous classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the origional column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df,name,target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x)==str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name,tv)\n",
    "        df[name2] = l\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# Regression chart, we will see more of this chart in the next class.\n",
    "def chart_regression(pred,y):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y_test.flatten()})\n",
    "    t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Get a new directory to hold checkpoints from a neural network.  This allows the neural network to be\n",
    "# loaded later.  If the erase param is set to true, the contents of the directory will be cleared.\n",
    "def get_model_dir(name,erase):\n",
    "    base_path = os.path.join(\".\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    if erase and len(model_dir)>4 and os.path.isdir(model_dir):\n",
    "        shutil.rmtree(model_dir,ignore_errors=True) # be careful, this deletes everything below the specified path\n",
    "    return model_dir\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name]-df[name].mean())>=(sd*df[name].std()))]\n",
    "    df.drop(drop_rows,axis=0,inplace=True)\n",
    "    \n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low =-1, normalized_high =1, \n",
    "                         data_low=None, data_high=None):\n",
    "    \n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    \n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "                * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogLoss Error\n",
    "\n",
    "Log loss is an error metric that is often used in place of accuracy for classification.  Log loss allows for \"partial credit\" when a miss classification occurs.  For example, a model might be used to classify A, B and C.  The correct answer might be A, however if the classification network chose B as having the highest probability, then accuracy gives the neural network no credit for this classification.  \n",
    "\n",
    "However, with log loss, the probability of the correct answer is added to the score.  For example, the correct answer might be A, but if the neural network only predicted .8 probability of A being correct, then the value -log(.8) is added.\n",
    "\n",
    "$$ logloss = -\\frac{1}{N}\\sum^N_{i=1}\\sum^M_{j=1}y_{ij} \\log(\\hat{y}_{ij}) $$\n",
    "\n",
    "The following table shows the logloss scores that correspond to the average predicted accuracy for the correct item. The **pred** column specifies the average probability for the correct class.  The **logloss** column specifies the log loss for that probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>0.105361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.000000e-01</td>\n",
       "      <td>0.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>0.356675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>0.510826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>0.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.203973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.500000e-02</td>\n",
       "      <td>2.590267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.500000e-02</td>\n",
       "      <td>3.688879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>18.420681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred    logloss\n",
       "0   1.000000e+00  -0.000000\n",
       "1   9.000000e-01   0.105361\n",
       "2   8.000000e-01   0.223144\n",
       "3   7.000000e-01   0.356675\n",
       "4   6.000000e-01   0.510826\n",
       "5   5.000000e-01   0.693147\n",
       "6   4.000000e-01   0.916291\n",
       "7   3.000000e-01   1.203973\n",
       "8   2.000000e-01   1.609438\n",
       "9   1.000000e-01   2.302585\n",
       "10  7.500000e-02   2.590267\n",
       "11  5.000000e-02   2.995732\n",
       "12  2.500000e-02   3.688879\n",
       "13  1.000000e-08  18.420681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "loss = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.075, 0.05, 0.025, 1e-8 ]\n",
    "\n",
    "df = pd.DataFrame({'pred':loss, 'logloss': -np.log(loss)},columns=['pred','logloss'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the opposit.  For a given logloss, what is the average probability for the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logloss</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.904837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.740818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.670320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.606531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.548812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.496585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.449329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.406570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.223130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.135335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.082085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.049787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.030197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.018316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logloss      pred\n",
       "0       0.1  0.904837\n",
       "1       0.2  0.818731\n",
       "2       0.3  0.740818\n",
       "3       0.4  0.670320\n",
       "4       0.5  0.606531\n",
       "5       0.6  0.548812\n",
       "6       0.7  0.496585\n",
       "7       0.8  0.449329\n",
       "8       0.9  0.406570\n",
       "9       1.0  0.367879\n",
       "10      1.5  0.223130\n",
       "11      2.0  0.135335\n",
       "12      2.5  0.082085\n",
       "13      3.0  0.049787\n",
       "14      3.5  0.030197\n",
       "15      4.0  0.018316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "loss = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 2.5, 3, 3.5, 4 ]\n",
    "\n",
    "df = pd.DataFrame({'logloss':loss, 'pred': np.exp(np.negative(loss))},\n",
    "                  columns=['logloss','pred'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluating Feature Importance\n",
    "\n",
    "Feature importance tells us how important each of the features (from the feature/import vector are to the prediction of a neural network, or other model.  There are many different ways to evaluate feature importance for neural networks.  The following paper presents a very good (and readable) overview of the various means of evaluating the importance of neural network inputs/features.\n",
    "\n",
    "Olden, J. D., Joy, M. K., & Death, R. G. (2004). [An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data](http://depts.washington.edu/oldenlab/wordpress/wp-content/uploads/2013/03/EcologicalModelling_2004.pdf). *Ecological Modelling*, 178(3), 389-397.\n",
    "\n",
    "In summary, the following methods are available to neural networks:\n",
    "\n",
    "* Connection Weights Algorithm\n",
    "* Partial Derivatives\n",
    "* Input Perturbation\n",
    "* Sensitivity Analysis\n",
    "* Forward Stepwise Addition \n",
    "* Improved Stepwise Selection 1\n",
    "* Backward Stepwise Elimination\n",
    "* Improved Stepwise Selection\n",
    "\n",
    "For this class we will use the **Input Perturbation** feature ranking algorithm.  This algorithm will work with any regression or classification network.  implementation of the input perturbation algorithm for scikit-learn is given in the next section. This algorithm is implemented in a function below that will work with any scikit-learn model.\n",
    "\n",
    "This algorithm was introduced by [Breiman](https://en.wikipedia.org/wiki/Leo_Breiman) in his seminal paper on random forests.  Although he presented this algorithm in conjunction with random forests, it is model-independent and appropriate for any supervised learning model.  This algorithm, known as the input perturbation algorithm, works by evaluating a trained model’s accuracy with each of the inputs individually shuffled from a data set.  Shuffling an input causes it to become useless—effectively removing it from the model. More important inputs will produce a less accurate score when they are removed by shuffling them. This process makes sense, because important features will contribute to the accuracy of the model.\n",
    "\n",
    "The provided algorithm will use logloss to evaluate a classification problem and RMSE for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def mlogloss(y_test, preds):\n",
    "    epsilon = 1e-15\n",
    "    sum = 0\n",
    "    for row in zip(preds,y_test):\n",
    "        x = row[0][row[1]]\n",
    "        x = max(epsilon,x)\n",
    "        x = min(1-epsilon,x)\n",
    "        sum+=math.log(x)\n",
    "    return( (-1/len(preds))*sum)\n",
    "\n",
    "def perturbation_rank(model, x, y, names, regression):\n",
    "    errors = []\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        hold = np.array(x[:, i])\n",
    "        np.random.shuffle(x[:, i])\n",
    "        \n",
    "        if regression:\n",
    "            # The following code is only needed until Google fixes SKCOMPAT\n",
    "            # pred = model.predict(x)\n",
    "            pred = list(model.predict(x_test, as_iterable=True))\n",
    "            error = metrics.mean_squared_error(y, pred)\n",
    "        else:\n",
    "            # The following code is only needed until Google fixes SKCOMPAT\n",
    "            # pred = model.predict_proba(x)\n",
    "            pred = list(model.predict_proba(x_test, as_iterable=True))\n",
    "            error = mlogloss(y, pred)\n",
    "            \n",
    "        errors.append(error)\n",
    "        x[:, i] = hold\n",
    "        \n",
    "    max_error = np.max(errors)\n",
    "    importance = [e/max_error for e in errors]\n",
    "   \n",
    "    data = {'name':names,'error':errors,'importance':importance}\n",
    "    result = pd.DataFrame(data, columns = ['name','error','importance'])\n",
    "    result.sort_values(by=['importance'], ascending=[0], inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Input Perturbation Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10b0effd0>, 'save_checkpoints_steps': None, '_environment': 'local', '_evaluation_master': '', '_is_chief': True, 'tf_random_seed': None, 'save_summary_steps': 100, 'keep_checkpoint_max': 5, '_num_ps_replicas': 0, 'save_checkpoints_secs': 1, '_master': '', '_task_id': 0, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'keep_checkpoint_every_n_hours': 10000, '_task_type': None}\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 0.938449, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.216566, step = 101\n",
      "INFO:tensorflow:global_step/sec: 135.35\n",
      "INFO:tensorflow:loss = 0.134559, step = 201\n",
      "INFO:tensorflow:global_step/sec: 560.812\n",
      "INFO:tensorflow:Saving checkpoints for 238 into ./dnn/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.100306, step = 301\n",
      "INFO:tensorflow:global_step/sec: 140.914\n",
      "INFO:tensorflow:loss = 0.0811362, step = 401\n",
      "INFO:tensorflow:global_step/sec: 366.664\n",
      "INFO:tensorflow:Saving checkpoints for 438 into ./dnn/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/iris\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 438.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 438: accuracy = 0.947368, loss = 0.138699\n",
      "INFO:tensorflow:Validation (step 500): accuracy = 0.947368, loss = 0.138699, global_step = 438\n",
      "INFO:tensorflow:loss = 0.0683095, step = 501\n",
      "INFO:tensorflow:global_step/sec: 48.4866\n",
      "INFO:tensorflow:Saving checkpoints for 501 into ./dnn/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.0594967, step = 601\n",
      "INFO:tensorflow:global_step/sec: 135.536\n",
      "INFO:tensorflow:loss = 0.0530703, step = 701\n",
      "INFO:tensorflow:global_step/sec: 751.721\n",
      "INFO:tensorflow:loss = 0.0481746, step = 801\n",
      "INFO:tensorflow:global_step/sec: 753.301\n",
      "INFO:tensorflow:Saving checkpoints for 801 into ./dnn/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.0442843, step = 901\n",
      "INFO:tensorflow:global_step/sec: 156.06\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/iris\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 801.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 801: accuracy = 0.921053, loss = 0.141667\n",
      "INFO:tensorflow:Validation (step 1000): accuracy = 0.921053, loss = 0.141667, global_step = 801\n",
      "INFO:tensorflow:Stopping. Best step: 500 with loss = 0.13869909942150116.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./dnn/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 0.0411022.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier at 0x115120b38>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification ranking\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "import numpy as np\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "\n",
    "# Set the desired TensorFlow output level for this example\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "path = \"./data/\"\n",
    "    \n",
    "filename = os.path.join(path,\"iris.csv\")    \n",
    "df = pd.read_csv(filename,na_values=['NA','?'])\n",
    "\n",
    "# Encode feature vector\n",
    "encode_numeric_zscore(df,'petal_w')\n",
    "encode_numeric_zscore(df,'petal_l')\n",
    "encode_numeric_zscore(df,'sepal_w')\n",
    "encode_numeric_zscore(df,'sepal_l')\n",
    "species = encode_text_index(df,\"species\")\n",
    "num_classes = len(species)\n",
    "\n",
    "# Create x & y for training\n",
    "\n",
    "# Create the x-side (feature vectors) of the training\n",
    "x, y = to_xy(df,'species')\n",
    "    \n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "# Get/clear a directory to store the neural network to\n",
    "model_dir = get_model_dir('iris',True)\n",
    "\n",
    "# Create a deep neural network with 3 hidden layers of 10, 20, 5\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[1])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir,\n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "    hidden_units=[10, 20, 5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "# Might be needed in future versions of \"TensorFlow Learn\"\n",
    "#classifier = learn.SKCompat(classifier) # For Sklearn compatibility\n",
    "\n",
    "# Early stopping\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    #metrics=validation_metrics,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "# Fit/train neural network\n",
    "classifier.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal_w</td>\n",
       "      <td>1.166125</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal_l</td>\n",
       "      <td>1.145329</td>\n",
       "      <td>0.982166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal_w</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.341289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal_l</td>\n",
       "      <td>0.154799</td>\n",
       "      <td>0.132747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name     error  importance\n",
       "3  petal_w  1.166125    1.000000\n",
       "2  petal_l  1.145329    0.982166\n",
       "1  sepal_w  0.397985    0.341289\n",
       "0  sepal_l  0.154799    0.132747"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the desired TensorFlow output level for this example\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Rank the features\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "names = df.columns.values[0:-1] # x column names\n",
    "rank = perturbation_rank(classifier, x_test, y_test, names, False)\n",
    "display(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Input Perturbation Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13f1b17f0>, 'save_checkpoints_steps': None, 'tf_random_seed': None, '_evaluation_master': '', '_environment': 'local', '_task_type': None, 'keep_checkpoint_every_n_hours': 10000, '_master': '', 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'keep_checkpoint_max': 5, '_is_chief': True, '_task_id': 0, 'save_checkpoints_secs': 1, '_num_ps_replicas': 0, 'save_summary_steps': 100}\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:320 in __init__.: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From <ipython-input-25-35da4834583a>:59 in <module>.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-25-35da4834583a>:59 in <module>.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 418.229, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Saving checkpoints for 75 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 15.2539, step = 101\n",
      "INFO:tensorflow:global_step/sec: 68.4061\n",
      "INFO:tensorflow:loss = 14.3478, step = 201\n",
      "INFO:tensorflow:global_step/sec: 341.022\n",
      "INFO:tensorflow:Saving checkpoints for 253 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 13.4674, step = 301\n",
      "INFO:tensorflow:global_step/sec: 148.007\n",
      "INFO:tensorflow:loss = 12.756, step = 401\n",
      "INFO:tensorflow:global_step/sec: 381.685\n",
      "INFO:tensorflow:Saving checkpoints for 428 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 428.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 428: loss = 8.44013\n",
      "INFO:tensorflow:Validation (step 500): loss = 8.44013, global_step = 428\n",
      "INFO:tensorflow:loss = 12.1986, step = 501\n",
      "INFO:tensorflow:global_step/sec: 58.9807\n",
      "INFO:tensorflow:Saving checkpoints for 501 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 11.8475, step = 601\n",
      "INFO:tensorflow:global_step/sec: 131.976\n",
      "INFO:tensorflow:Saving checkpoints for 697 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 11.7276, step = 701\n",
      "INFO:tensorflow:global_step/sec: 140.924\n",
      "INFO:tensorflow:loss = 11.4078, step = 801\n",
      "INFO:tensorflow:global_step/sec: 225.613\n",
      "INFO:tensorflow:Saving checkpoints for 814 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 11.3159, step = 901\n",
      "INFO:tensorflow:global_step/sec: 125.198\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 814.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 814: loss = 7.88651\n",
      "INFO:tensorflow:Validation (step 1000): loss = 7.88651, global_step = 814\n",
      "INFO:tensorflow:loss = 11.1019, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 137.67\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 11.0134, step = 1101\n",
      "INFO:tensorflow:global_step/sec: 124.415\n",
      "INFO:tensorflow:Saving checkpoints for 1179 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 10.951, step = 1201\n",
      "INFO:tensorflow:global_step/sec: 144.149\n",
      "INFO:tensorflow:loss = 10.8157, step = 1301\n",
      "INFO:tensorflow:global_step/sec: 306.405\n",
      "INFO:tensorflow:Saving checkpoints for 1355 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 10.6879, step = 1401\n",
      "INFO:tensorflow:global_step/sec: 126.608\n",
      "INFO:tensorflow:Saving checkpoints for 1491 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 1491.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 1491: loss = 7.6846\n",
      "INFO:tensorflow:Validation (step 1500): loss = 7.6846, global_step = 1491\n",
      "INFO:tensorflow:loss = 10.6112, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 84.4668\n",
      "INFO:tensorflow:Saving checkpoints for 1565 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 10.5216, step = 1601\n",
      "INFO:tensorflow:global_step/sec: 132.274\n",
      "INFO:tensorflow:loss = 10.4495, step = 1701\n",
      "INFO:tensorflow:global_step/sec: 276.35\n",
      "INFO:tensorflow:Saving checkpoints for 1740 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 10.4016, step = 1801\n",
      "INFO:tensorflow:global_step/sec: 159.76\n",
      "INFO:tensorflow:loss = 10.3378, step = 1901\n",
      "INFO:tensorflow:global_step/sec: 397.137\n",
      "INFO:tensorflow:Saving checkpoints for 1985 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 1985.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 1985: loss = 7.44325\n",
      "INFO:tensorflow:Validation (step 2000): loss = 7.44325, global_step = 1985\n",
      "INFO:tensorflow:loss = 10.267, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 92.6539\n",
      "INFO:tensorflow:Saving checkpoints for 2052 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 10.2214, step = 2101\n",
      "INFO:tensorflow:global_step/sec: 143.366\n",
      "INFO:tensorflow:loss = 10.103, step = 2201\n",
      "INFO:tensorflow:global_step/sec: 317.05\n",
      "INFO:tensorflow:Saving checkpoints for 2251 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 10.1747, step = 2301\n",
      "INFO:tensorflow:global_step/sec: 153.355\n",
      "INFO:tensorflow:loss = 10.5667, step = 2401\n",
      "INFO:tensorflow:global_step/sec: 290.426\n",
      "INFO:tensorflow:Saving checkpoints for 2432 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 2432.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 2432: loss = 7.28457\n",
      "INFO:tensorflow:Validation (step 2500): loss = 7.28457, global_step = 2432\n",
      "INFO:tensorflow:loss = 9.87144, step = 2501\n",
      "INFO:tensorflow:global_step/sec: 82.2301\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.85946, step = 2601\n",
      "INFO:tensorflow:global_step/sec: 129.48\n",
      "INFO:tensorflow:Saving checkpoints for 2668 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 10.0071, step = 2701\n",
      "INFO:tensorflow:global_step/sec: 143.862\n",
      "INFO:tensorflow:loss = 9.71904, step = 2801\n",
      "INFO:tensorflow:global_step/sec: 251.072\n",
      "INFO:tensorflow:Saving checkpoints for 2835 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.72212, step = 2901\n",
      "INFO:tensorflow:global_step/sec: 97.151\n",
      "INFO:tensorflow:Saving checkpoints for 2923 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 2923.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 2923: loss = 6.89964\n",
      "INFO:tensorflow:Validation (step 3000): loss = 6.89964, global_step = 2923\n",
      "INFO:tensorflow:loss = 10.1996, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 65.4069\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.66477, step = 3101\n",
      "INFO:tensorflow:global_step/sec: 110.503\n",
      "INFO:tensorflow:Saving checkpoints for 3135 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.79317, step = 3201\n",
      "INFO:tensorflow:global_step/sec: 150.385\n",
      "INFO:tensorflow:loss = 9.6339, step = 3301\n",
      "INFO:tensorflow:global_step/sec: 382.973\n",
      "INFO:tensorflow:Saving checkpoints for 3352 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.57308, step = 3401\n",
      "INFO:tensorflow:global_step/sec: 139.935\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 3352.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 3352: loss = 6.7372\n",
      "INFO:tensorflow:Validation (step 3500): loss = 6.7372, global_step = 3352\n",
      "INFO:tensorflow:loss = 9.54135, step = 3501\n",
      "INFO:tensorflow:global_step/sec: 129.52\n",
      "INFO:tensorflow:Saving checkpoints for 3501 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.51521, step = 3601\n",
      "INFO:tensorflow:global_step/sec: 129.779\n",
      "INFO:tensorflow:Saving checkpoints for 3665 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.46312, step = 3701\n",
      "INFO:tensorflow:global_step/sec: 147.398\n",
      "INFO:tensorflow:loss = 9.41999, step = 3801\n",
      "INFO:tensorflow:global_step/sec: 288.399\n",
      "INFO:tensorflow:Saving checkpoints for 3860 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.34979, step = 3901\n",
      "INFO:tensorflow:global_step/sec: 126.79\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 3860.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 3860: loss = 6.46572\n",
      "INFO:tensorflow:Validation (step 4000): loss = 6.46572, global_step = 3860\n",
      "INFO:tensorflow:loss = 9.24783, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 141.305\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.03982, step = 4101\n",
      "INFO:tensorflow:global_step/sec: 107.597\n",
      "INFO:tensorflow:Saving checkpoints for 4118 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 8.99606, step = 4201\n",
      "INFO:tensorflow:global_step/sec: 101.061\n",
      "INFO:tensorflow:Saving checkpoints for 4220 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.02895, step = 4301\n",
      "INFO:tensorflow:global_step/sec: 133.722\n",
      "INFO:tensorflow:Saving checkpoints for 4374 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 8.99774, step = 4401\n",
      "INFO:tensorflow:global_step/sec: 92.2167\n",
      "INFO:tensorflow:Saving checkpoints for 4447 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 4447.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 4447: loss = 6.25561\n",
      "INFO:tensorflow:Validation (step 4500): loss = 6.25561, global_step = 4447\n",
      "INFO:tensorflow:loss = 8.86298, step = 4501\n",
      "INFO:tensorflow:global_step/sec: 61.9502\n",
      "INFO:tensorflow:Saving checkpoints for 4501 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Saving checkpoints for 4596 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 8.82492, step = 4601\n",
      "INFO:tensorflow:global_step/sec: 66.321\n",
      "INFO:tensorflow:loss = 9.11868, step = 4701\n",
      "INFO:tensorflow:global_step/sec: 247.175\n",
      "INFO:tensorflow:Saving checkpoints for 4724 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 8.76793, step = 4801\n",
      "INFO:tensorflow:global_step/sec: 107.868\n",
      "INFO:tensorflow:Saving checkpoints for 4823 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 9.12902, step = 4901\n",
      "INFO:tensorflow:global_step/sec: 101.333\n",
      "INFO:tensorflow:Saving checkpoints for 4933 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/jeff/anaconda/envs/gpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:710 in every_n_step_end.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\n",
      "INFO:tensorflow:Restored model from ./dnn/mpg\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 4933.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 4933: loss = 6.3186\n",
      "INFO:tensorflow:Validation (step 5000): loss = 6.3186, global_step = 4933\n",
      "INFO:tensorflow:Stopping. Best step: 4500 with loss = 6.255606651306152.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ./dnn/mpg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 8.76327.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(optimizer=None, feature_columns=[_RealValuedColumn(column_name='', dimension=398, default_value=None, dtype=tf.float32, normalizer=None)], dropout=None, hidden_units=[50, 25, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "# Set the desired TensorFlow output level for this example\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "# create feature vector\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name',1,inplace=True)\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'cylinders')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "# Encode to a 2D matrix for training\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Get/clear a directory to store the neural network to\n",
    "model_dir = get_model_dir('mpg',True)\n",
    "\n",
    "# Create a deep neural network with 3 hidden layers of 50, 25, 10\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[1])]\n",
    "regressor = learn.DNNRegressor(\n",
    "    model_dir= model_dir,\n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[50, 25, 10])\n",
    "\n",
    "# Might be needed in future versions of \"TensorFlow Learn\"\n",
    "#classifier = learn.SKCompat(classifier) # For Sklearn compatibility\n",
    "\n",
    "# Early stopping\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "# Fit/train neural network\n",
    "regressor.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>horsepower</td>\n",
       "      <td>25.487295</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight</td>\n",
       "      <td>23.591404</td>\n",
       "      <td>0.925614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year</td>\n",
       "      <td>13.226979</td>\n",
       "      <td>0.518964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>displacement</td>\n",
       "      <td>10.212932</td>\n",
       "      <td>0.400707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>8.685765</td>\n",
       "      <td>0.340788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>origin-1</td>\n",
       "      <td>8.395874</td>\n",
       "      <td>0.329414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>origin-2</td>\n",
       "      <td>7.903455</td>\n",
       "      <td>0.310094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>7.881567</td>\n",
       "      <td>0.309235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>origin-3</td>\n",
       "      <td>7.494909</td>\n",
       "      <td>0.294064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name      error  importance\n",
       "2    horsepower  25.487295    1.000000\n",
       "3        weight  23.591404    0.925614\n",
       "5          year  13.226979    0.518964\n",
       "1  displacement  10.212932    0.400707\n",
       "4  acceleration   8.685765    0.340788\n",
       "6      origin-1   8.395874    0.329414\n",
       "7      origin-2   7.903455    0.310094\n",
       "0     cylinders   7.881567    0.309235\n",
       "8      origin-3   7.494909    0.294064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the desired TensorFlow output level for this example\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Rank the features\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "names = df.columns.values[1:] # x column names\n",
    "rank = perturbation_rank(regressor, x_test, y_test, names, True)\n",
    "display(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Biological Response Data Set\n",
    "\n",
    "* [Biological Response Dataset at Kaggle](https://www.kaggle.com/c/bioresponse)\n",
    "* [1st place interview for Boehringer Ingelheim Biological Response](http://blog.kaggle.com/2012/07/05/1st-place-interview-for-boehringer-ingelheim-biological-response/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as skflow\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_train = os.path.join(path,\"bio_train.csv\")\n",
    "filename_test = os.path.join(path,\"bio_test.csv\")\n",
    "filename_submit = os.path.join(path,\"bio_submit.csv\")\n",
    "df_train = pd.read_csv(filename_train,na_values=['NA','?'])\n",
    "df_test = pd.read_csv(filename_test,na_values=['NA','?'])\n",
    "\n",
    "activity_classes = encode_text_index(df_train,'Activity')\n",
    "\n",
    "#display(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Response with Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting/Training...\n",
      "Fitting done...\n",
      "Validation logloss: 1.3024759304987723\n",
      "Validation accuracy score: 0.7835820895522388\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Set the desired TensorFlow output level for this example\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Encode feature vector\n",
    "x, y = to_xy(df_train,'Activity')\n",
    "x_submit = df_test.as_matrix().astype(np.float32)\n",
    "num_classes = len(activity_classes)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42) \n",
    "\n",
    "\n",
    "# Get/clear a directory to store the neural network to\n",
    "model_dir = get_model_dir('bio',True)\n",
    "\n",
    "# Create a deep neural network with 4 hidden layers of [500, 250, 100, 50]\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[1])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir,\n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=60),\n",
    "    hidden_units=[500, 250, 100, 50], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "# Might be needed in future versions of \"TensorFlow Learn\"\n",
    "#classifier = learn.SKCompat(classifier) # For Sklearn compatibility\n",
    "\n",
    "# Early stopping\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    #metrics=validation_metrics,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "# Fit/train neural network\n",
    "print(\"Fitting/Training...\")\n",
    "classifier.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "print(\"Fitting done...\")\n",
    "\n",
    "# Give logloss error\n",
    "pred = np.array(list(classifier.predict_proba(x_test, as_iterable=True)))\n",
    "pred = pred[:,1]\n",
    "# Clip so that min is never exactly 0, max never 1\n",
    "pred = np.clip(pred,a_min=1e-6,a_max=(1-1e-6)) \n",
    "print(\"Validation logloss: {}\".format(sklearn.metrics.log_loss(y_test,pred)))\n",
    "\n",
    "# Evaluate success using accuracy\n",
    "pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"Validation accuracy score: {}\".format(score))\n",
    "\n",
    "# Build a submission file\n",
    "pred_submit = np.array(list(classifier.predict_proba(x_submit, as_iterable=True)))\n",
    "pred_submit = pred_submit[:,1]\n",
    "# Clip so that min is never exactly 0, max never 1\n",
    "pred = np.clip(pred,a_min=1e-6,a_max=(1-1e-6)) \n",
    "submit_df = pd.DataFrame({'MoleculeId':[x+1 for x in range(len(pred_submit))],'PredictedProbability':pred_submit})\n",
    "submit_df.to_csv(filename_submit, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array(list(classifier.predict_proba(x_test, as_iterable=True)))\n",
    "pred = pred[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   1.00000000e+00]\n",
      " [  9.99718249e-01   1.00000000e+00]\n",
      " [  6.02514367e-04   0.00000000e+00]\n",
      " ..., \n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  1.70188039e-04   0.00000000e+00]\n",
      " [  4.79252189e-01   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(list(zip(pred,y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Features/Columns are Important \n",
    "\n",
    "The following uses perturbation ranking to evaluate the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>D26</td>\n",
       "      <td>1.927250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>D50</td>\n",
       "      <td>1.636884</td>\n",
       "      <td>0.849337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>D959</td>\n",
       "      <td>1.636834</td>\n",
       "      <td>0.849311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>D1021</td>\n",
       "      <td>1.627036</td>\n",
       "      <td>0.844227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>D1066</td>\n",
       "      <td>1.623286</td>\n",
       "      <td>0.842281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>D200</td>\n",
       "      <td>1.620021</td>\n",
       "      <td>0.840587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>D1370</td>\n",
       "      <td>1.619655</td>\n",
       "      <td>0.840397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>D1152</td>\n",
       "      <td>1.619063</td>\n",
       "      <td>0.840090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>D1187</td>\n",
       "      <td>1.618359</td>\n",
       "      <td>0.839725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>D978</td>\n",
       "      <td>1.618107</td>\n",
       "      <td>0.839594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>D1166</td>\n",
       "      <td>1.617221</td>\n",
       "      <td>0.839134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>D975</td>\n",
       "      <td>1.616965</td>\n",
       "      <td>0.839001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>D1265</td>\n",
       "      <td>1.616720</td>\n",
       "      <td>0.838874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>D1119</td>\n",
       "      <td>1.616659</td>\n",
       "      <td>0.838843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>D1062</td>\n",
       "      <td>1.616600</td>\n",
       "      <td>0.838812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>D1444</td>\n",
       "      <td>1.615629</td>\n",
       "      <td>0.838308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>D193</td>\n",
       "      <td>1.615430</td>\n",
       "      <td>0.838205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>D1220</td>\n",
       "      <td>1.615394</td>\n",
       "      <td>0.838186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>D1127</td>\n",
       "      <td>1.614842</td>\n",
       "      <td>0.837900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>D957</td>\n",
       "      <td>1.614777</td>\n",
       "      <td>0.837866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>D1186</td>\n",
       "      <td>1.614675</td>\n",
       "      <td>0.837813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>D1269</td>\n",
       "      <td>1.614604</td>\n",
       "      <td>0.837776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>D1430</td>\n",
       "      <td>1.614581</td>\n",
       "      <td>0.837764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>D1095</td>\n",
       "      <td>1.614347</td>\n",
       "      <td>0.837643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>D1319</td>\n",
       "      <td>1.614259</td>\n",
       "      <td>0.837597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>D1110</td>\n",
       "      <td>1.613762</td>\n",
       "      <td>0.837339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>D1008</td>\n",
       "      <td>1.613502</td>\n",
       "      <td>0.837204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>D1045</td>\n",
       "      <td>1.613208</td>\n",
       "      <td>0.837052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>D1354</td>\n",
       "      <td>1.613049</td>\n",
       "      <td>0.836969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>D1202</td>\n",
       "      <td>1.612769</td>\n",
       "      <td>0.836824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>D1183</td>\n",
       "      <td>1.591882</td>\n",
       "      <td>0.825986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>D1061</td>\n",
       "      <td>1.591706</td>\n",
       "      <td>0.825895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>D1010</td>\n",
       "      <td>1.591375</td>\n",
       "      <td>0.825723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>D1402</td>\n",
       "      <td>1.591371</td>\n",
       "      <td>0.825721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>D980</td>\n",
       "      <td>1.591366</td>\n",
       "      <td>0.825718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>D218</td>\n",
       "      <td>1.590905</td>\n",
       "      <td>0.825479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>D1011</td>\n",
       "      <td>1.590292</td>\n",
       "      <td>0.825161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>D965</td>\n",
       "      <td>1.590159</td>\n",
       "      <td>0.825092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>D958</td>\n",
       "      <td>1.589986</td>\n",
       "      <td>0.825003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>D953</td>\n",
       "      <td>1.589517</td>\n",
       "      <td>0.824759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>D1077</td>\n",
       "      <td>1.589494</td>\n",
       "      <td>0.824747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>D1433</td>\n",
       "      <td>1.589242</td>\n",
       "      <td>0.824616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>D1163</td>\n",
       "      <td>1.587849</td>\n",
       "      <td>0.823894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>D1337</td>\n",
       "      <td>1.587128</td>\n",
       "      <td>0.823520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>D1063</td>\n",
       "      <td>1.587017</td>\n",
       "      <td>0.823462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>D963</td>\n",
       "      <td>1.586860</td>\n",
       "      <td>0.823381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>D1003</td>\n",
       "      <td>1.586529</td>\n",
       "      <td>0.823209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>D1194</td>\n",
       "      <td>1.586382</td>\n",
       "      <td>0.823133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>D1414</td>\n",
       "      <td>1.586371</td>\n",
       "      <td>0.823127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>D971</td>\n",
       "      <td>1.586318</td>\n",
       "      <td>0.823099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>D1174</td>\n",
       "      <td>1.585553</td>\n",
       "      <td>0.822702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>D974</td>\n",
       "      <td>1.584977</td>\n",
       "      <td>0.822403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>D1175</td>\n",
       "      <td>1.584557</td>\n",
       "      <td>0.822185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>D1308</td>\n",
       "      <td>1.583719</td>\n",
       "      <td>0.821751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>D1168</td>\n",
       "      <td>1.583492</td>\n",
       "      <td>0.821633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>D1074</td>\n",
       "      <td>1.582063</td>\n",
       "      <td>0.820892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>D1055</td>\n",
       "      <td>1.581092</td>\n",
       "      <td>0.820388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>D1086</td>\n",
       "      <td>1.578629</td>\n",
       "      <td>0.819109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>D1182</td>\n",
       "      <td>1.578356</td>\n",
       "      <td>0.818968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>D973</td>\n",
       "      <td>1.576500</td>\n",
       "      <td>0.818005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1776 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name     error  importance\n",
       "26      D26  1.927250    1.000000\n",
       "50      D50  1.636884    0.849337\n",
       "959    D959  1.636834    0.849311\n",
       "1021  D1021  1.627036    0.844227\n",
       "1066  D1066  1.623286    0.842281\n",
       "200    D200  1.620021    0.840587\n",
       "1370  D1370  1.619655    0.840397\n",
       "1152  D1152  1.619063    0.840090\n",
       "1187  D1187  1.618359    0.839725\n",
       "978    D978  1.618107    0.839594\n",
       "1166  D1166  1.617221    0.839134\n",
       "975    D975  1.616965    0.839001\n",
       "1265  D1265  1.616720    0.838874\n",
       "1119  D1119  1.616659    0.838843\n",
       "1062  D1062  1.616600    0.838812\n",
       "1444  D1444  1.615629    0.838308\n",
       "193    D193  1.615430    0.838205\n",
       "1220  D1220  1.615394    0.838186\n",
       "1127  D1127  1.614842    0.837900\n",
       "957    D957  1.614777    0.837866\n",
       "1186  D1186  1.614675    0.837813\n",
       "1269  D1269  1.614604    0.837776\n",
       "1430  D1430  1.614581    0.837764\n",
       "1095  D1095  1.614347    0.837643\n",
       "1319  D1319  1.614259    0.837597\n",
       "1110  D1110  1.613762    0.837339\n",
       "1008  D1008  1.613502    0.837204\n",
       "1045  D1045  1.613208    0.837052\n",
       "1354  D1354  1.613049    0.836969\n",
       "1202  D1202  1.612769    0.836824\n",
       "...     ...       ...         ...\n",
       "1183  D1183  1.591882    0.825986\n",
       "1061  D1061  1.591706    0.825895\n",
       "1010  D1010  1.591375    0.825723\n",
       "1402  D1402  1.591371    0.825721\n",
       "980    D980  1.591366    0.825718\n",
       "218    D218  1.590905    0.825479\n",
       "1011  D1011  1.590292    0.825161\n",
       "965    D965  1.590159    0.825092\n",
       "958    D958  1.589986    0.825003\n",
       "953    D953  1.589517    0.824759\n",
       "1077  D1077  1.589494    0.824747\n",
       "1433  D1433  1.589242    0.824616\n",
       "1163  D1163  1.587849    0.823894\n",
       "1337  D1337  1.587128    0.823520\n",
       "1063  D1063  1.587017    0.823462\n",
       "963    D963  1.586860    0.823381\n",
       "1003  D1003  1.586529    0.823209\n",
       "1194  D1194  1.586382    0.823133\n",
       "1414  D1414  1.586371    0.823127\n",
       "971    D971  1.586318    0.823099\n",
       "1174  D1174  1.585553    0.822702\n",
       "974    D974  1.584977    0.822403\n",
       "1175  D1175  1.584557    0.822185\n",
       "1308  D1308  1.583719    0.821751\n",
       "1168  D1168  1.583492    0.821633\n",
       "1074  D1074  1.582063    0.820892\n",
       "1055  D1055  1.581092    0.820388\n",
       "1086  D1086  1.578629    0.819109\n",
       "1182  D1182  1.578356    0.818968\n",
       "973    D973  1.576500    0.818005\n",
       "\n",
       "[1776 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the desired TensorFlow output level for this example\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Rank the features\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "names = df_train.columns.values[0:-1] # x column names\n",
    "rank = perturbation_rank(classifier, x_test, y_test, names, False)\n",
    "display(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Response with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insample logloss: 0.12571285789055234\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "\n",
    "\n",
    "x, y = to_xy(df_train,'Activity')\n",
    "y = y.ravel() # Make y just a 1D array, as required by random forest\n",
    "x_test = df_test.as_matrix().astype(np.float32)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(x, y)\n",
    "pred = rf.predict_proba(x_test)\n",
    "pred = pred[:,1]\n",
    "pred_insample = rf.predict_proba(x)\n",
    "pred_insample = pred_insample[:,1]\n",
    "\n",
    "submit_df = pd.DataFrame({'MoleculeId':[x+1 for x in range(len(pred))],'PredictedProbability':pred})\n",
    "submit_df.to_csv(filename_submit, index=False)\n",
    "print(\"Insample logloss: {}\".format(sklearn.metrics.log_loss(y,pred_insample)))\n",
    "#display(submit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Bagging\n",
    "\n",
    "Neural networks will typically achieve better results when they are bagged.  Bagging a neural network is a process where the same neural network is trained over and over and the results are averaged together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Model: 0 : <tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x0000020598BE8630>\n",
      "Fold #0: loss=0.41971067017404995\n",
      "Fold #1: loss=0.33424993056806734\n",
      "Fold #2: loss=0.3571527327864354\n",
      "Fold #3: loss=0.2970918889468416\n",
      "Fold #4: loss=0.3301752010517648\n",
      "Fold #5: loss=0.3377331461482012\n",
      "Fold #6: loss=0.20413984968653634\n",
      "Fold #7: loss=0.33457021469956666\n",
      "Fold #8: loss=0.34963052553945656\n",
      "Fold #9: loss=0.4366637295322299\n",
      "DNNClassifier: Mean loss=0.340111788913315\n",
      "Model: 1 : <tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x00000205985E7748>\n",
      "Fold #0: loss=0.41971067017404995\n",
      "Fold #1: loss=0.33424993056806734\n",
      "Fold #2: loss=0.3571527327864354\n",
      "Fold #3: loss=0.2970918889468416\n",
      "Fold #4: loss=0.3301752010517648\n",
      "Fold #5: loss=0.3377331461482012\n",
      "Fold #6: loss=0.20413984968653634\n",
      "Fold #7: loss=0.33457021469956666\n",
      "Fold #8: loss=0.34963052553945656\n",
      "Fold #9: loss=0.4366637295322299\n",
      "DNNClassifier: Mean loss=0.340111788913315\n",
      "Model: 2 : <tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x00000205985E7978>\n",
      "Fold #0: loss=0.41971067017404995\n",
      "Fold #1: loss=0.33424993056806734\n",
      "Fold #2: loss=0.3571527327864354\n",
      "Fold #3: loss=0.2970918889468416\n",
      "Fold #4: loss=0.3301752010517648\n",
      "Fold #5: loss=0.3377331461482012\n",
      "Fold #6: loss=0.20413984968653634\n",
      "Fold #7: loss=0.33457021469956666\n",
      "Fold #8: loss=0.34963052553945656\n",
      "Fold #9: loss=0.4366637295322299\n",
      "DNNClassifier: Mean loss=0.340111788913315\n",
      "Model: 3 : <tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x00000205985E7BA8>\n",
      "Fold #0: loss=0.41971067017404995\n",
      "Fold #1: loss=0.33424993056806734\n",
      "Fold #2: loss=0.3571527327864354\n",
      "Fold #3: loss=0.2970918889468416\n",
      "Fold #4: loss=0.3301752010517648\n",
      "Fold #5: loss=0.3377331461482012\n",
      "Fold #6: loss=0.20413984968653634\n",
      "Fold #7: loss=0.33457021469956666\n",
      "Fold #8: loss=0.34963052553945656\n",
      "Fold #9: loss=0.4366637295322299\n",
      "DNNClassifier: Mean loss=0.340111788913315\n",
      "Model: 4 : <tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x00000205985E7DD8>\n",
      "Fold #0: loss=0.41971067017404995\n",
      "Fold #1: loss=0.33424993056806734\n",
      "Fold #2: loss=0.3571527327864354\n",
      "Fold #3: loss=0.2970918889468416\n",
      "Fold #4: loss=0.3301752010517648\n",
      "Fold #5: loss=0.3377331461482012\n",
      "Fold #6: loss=0.20413984968653634\n",
      "Fold #7: loss=0.33457021469956666\n",
      "Fold #8: loss=0.34963052553945656\n",
      "Fold #9: loss=0.4366637295322299\n",
      "DNNClassifier: Mean loss=0.340111788913315\n",
      "\n",
      "Blending models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow.contrib.learn as learn\n",
    "\n",
    "PATH = \"./data/\"\n",
    "SHUFFLE = False\n",
    "FOLDS = 10\n",
    "\n",
    "def mlogloss(y_test, preds):\n",
    "    epsilon = 1e-15\n",
    "    sum = 0\n",
    "    for row in zip(preds,y_test):\n",
    "        x = row[0][row[1]]\n",
    "        x = max(epsilon,x)\n",
    "        x = min(1-epsilon,x)\n",
    "        sum+=math.log(x)\n",
    "    return( (-1/len(preds))*sum)\n",
    "\n",
    "def stretch(y):\n",
    "    return (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "\n",
    "def blend_ensemble(x, y, x_submit):\n",
    "\n",
    "    folds = list(StratifiedKFold(y, FOLDS))\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "\n",
    "    models = [\n",
    "        learn.DNNClassifier(hidden_units=[100, 50, 25, 5], n_classes=2, feature_columns=feature_columns),  # steps=1000\n",
    "        learn.DNNClassifier(hidden_units=[100, 50, 25, 5], n_classes=2, feature_columns=feature_columns), # steps=500\n",
    "        learn.DNNClassifier(hidden_units=[200, 100, 50, 25], n_classes=2, feature_columns=feature_columns), # steps=1000\n",
    "        learn.DNNClassifier(hidden_units=[200, 100, 50, 25], n_classes=2, feature_columns=feature_columns), # steps=500\n",
    "        learn.DNNClassifier(hidden_units=[50, 25, 5], n_classes=2, feature_columns=feature_columns)] #steps=500\n",
    "\n",
    "    dataset_blend_train = np.zeros((x.shape[0], len(models)))\n",
    "    dataset_blend_test = np.zeros((x_submit.shape[0], len(models)))\n",
    "\n",
    "    for j, model in enumerate(models):\n",
    "        print(\"Model: {} : {}\".format(j, model) )\n",
    "        fold_sums = np.zeros((x_submit.shape[0], len(folds)))\n",
    "        total_loss = 0\n",
    "        for i, (train, test) in enumerate(folds):\n",
    "            x_train = x[train]\n",
    "            y_train = y[train]\n",
    "            x_test = x[test]\n",
    "            y_test = y[test]\n",
    "            model.fit(x_train, y_train,steps=10)\n",
    "            pred = np.array(list(classifier.predict_proba(x_test, as_iterable=True)))\n",
    "            # pred = model.predict_proba(x_test)\n",
    "            dataset_blend_train[test, j] = pred[:, 1]\n",
    "            pred2 = np.array(list(classifier.predict_proba(x_submit, as_iterable=True)))\n",
    "            #fold_sums[:, i] = model.predict_proba(x_submit)[:, 1]\n",
    "            fold_sums[:, i] = pred2[:, 1]\n",
    "            loss = mlogloss(y_test, pred)\n",
    "            total_loss+=loss\n",
    "            print(\"Fold #{}: loss={}\".format(i,loss))\n",
    "        print(\"{}: Mean loss={}\".format(model.__class__.__name__,total_loss/len(folds)))\n",
    "        dataset_blend_test[:, j] = fold_sums.mean(1)\n",
    "\n",
    "    print()\n",
    "    print(\"Blending models.\")\n",
    "    blend = LogisticRegression()\n",
    "    blend.fit(dataset_blend_train, y)\n",
    "    return blend.predict_proba(dataset_blend_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(42)  # seed to shuffle the train set\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    filename_train = os.path.join(PATH, \"bio_train.csv\")\n",
    "    df_train = pd.read_csv(filename_train, na_values=['NA', '?'])\n",
    "\n",
    "    filename_submit = os.path.join(PATH, \"bio_test.csv\")\n",
    "    df_submit = pd.read_csv(filename_submit, na_values=['NA', '?'])\n",
    "\n",
    "    predictors = list(df_train.columns.values)\n",
    "    predictors.remove('Activity')\n",
    "    x = df_train.as_matrix(predictors)\n",
    "    y = df_train['Activity']\n",
    "    x_submit = df_submit.as_matrix()\n",
    "\n",
    "    if SHUFFLE:\n",
    "        idx = np.random.permutation(y.size)\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "    submit_data = blend_ensemble(x, y, x_submit)\n",
    "    submit_data = stretch(submit_data)\n",
    "\n",
    "    ####################\n",
    "    # Build submit file\n",
    "    ####################\n",
    "    ids = [id+1 for id in range(submit_data.shape[0])]\n",
    "    submit_filename = os.path.join(PATH, \"bio_submit.csv\")\n",
    "    submit_df = pd.DataFrame({'MoleculeId': ids, 'PredictedProbability': submit_data[:, 1]},\n",
    "                             columns=['MoleculeId','PredictedProbability'])\n",
    "    submit_df.to_csv(submit_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Ensemble\n",
    "\n",
    "A neural network ensemble combines neural network predictions with other models.  The exact blend of all of these models is determined by logistic regression.  The following code performs this blend for a classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Model: 0 : <tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x00000205ACD40C50>\n",
      "Fold #0: loss=0.41971067017404995\n",
      "Fold #1: loss=0.33424993056806734\n",
      "Fold #2: loss=0.3571527327864354\n",
      "Fold #3: loss=0.2970918889468416\n",
      "Fold #4: loss=0.3301752010517648\n",
      "Fold #5: loss=0.3377331461482012\n",
      "Fold #6: loss=0.20413984968653634\n",
      "Fold #7: loss=0.33457021469956666\n",
      "Fold #8: loss=0.34963052553945656\n",
      "Fold #9: loss=0.4366637295322299\n",
      "DNNClassifier: Mean loss=0.340111788913315\n",
      "Model: 1 : KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "Fold #0: loss=3.606678388314123\n",
      "Fold #1: loss=2.2197228940978317\n",
      "Fold #2: loss=3.6717523663107237\n",
      "Fold #3: loss=2.5045156203944594\n",
      "Fold #4: loss=4.443553550438037\n",
      "Fold #5: loss=4.410524301688227\n",
      "Fold #6: loss=3.400455469543658\n",
      "Fold #7: loss=3.0885474338547683\n",
      "Fold #8: loss=2.1219335323249253\n",
      "Fold #9: loss=3.0613772690497245\n",
      "KNeighborsClassifier: Mean loss=3.2529060826016476\n",
      "Model: 2 : RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "Fold #0: loss=0.4656951886598634\n",
      "Fold #1: loss=0.42616738372828994\n",
      "Fold #2: loss=0.5553310672072804\n",
      "Fold #3: loss=0.4158882703480888\n",
      "Fold #4: loss=0.47961750744493736\n",
      "Fold #5: loss=0.4818691257035154\n",
      "Fold #6: loss=0.4077640145387344\n",
      "Fold #7: loss=0.4765886929423487\n",
      "Fold #8: loss=0.4517642970846355\n",
      "Fold #9: loss=0.4680612294852455\n",
      "RandomForestClassifier: Mean loss=0.46287467771429397\n",
      "Model: 3 : RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "Fold #0: loss=0.4517180829333204\n",
      "Fold #1: loss=0.4288138331194263\n",
      "Fold #2: loss=0.48381057653259435\n",
      "Fold #3: loss=0.4182666851649727\n",
      "Fold #4: loss=0.48153896166957655\n",
      "Fold #5: loss=0.4980753099535686\n",
      "Fold #6: loss=0.40137715472145985\n",
      "Fold #7: loss=0.45485344988166004\n",
      "Fold #8: loss=0.4468679233769468\n",
      "Fold #9: loss=0.46952543963188276\n",
      "RandomForestClassifier: Mean loss=0.4534847416985408\n",
      "Model: 4 : ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold #0: loss=0.45496751079363495\n",
      "Fold #1: loss=0.4221988146584036\n",
      "Fold #2: loss=0.5864779075767735\n",
      "Fold #3: loss=0.4135387147555288\n",
      "Fold #4: loss=0.49165543640777337\n",
      "Fold #5: loss=0.5826853127129209\n",
      "Fold #6: loss=0.4992293347545809\n",
      "Fold #7: loss=0.5696776278324083\n",
      "Fold #8: loss=0.5377009614825886\n",
      "Fold #9: loss=0.6233110429105153\n",
      "ExtraTreesClassifier: Mean loss=0.5181442663885129\n",
      "Model: 5 : ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold #0: loss=0.44825346440152214\n",
      "Fold #1: loss=0.40736044850901787\n",
      "Fold #2: loss=0.5775460796610716\n",
      "Fold #3: loss=0.42126274280011555\n",
      "Fold #4: loss=0.4949968282719872\n",
      "Fold #5: loss=0.5074636989761913\n",
      "Fold #6: loss=0.4176899941799664\n",
      "Fold #7: loss=0.6431685288404098\n",
      "Fold #8: loss=0.5444145998368657\n",
      "Fold #9: loss=0.46770812815232515\n",
      "ExtraTreesClassifier: Mean loss=0.4929864513629473\n",
      "Model: 6 : GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='deviance', max_depth=6,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=50, presort='auto', random_state=None,\n",
      "              subsample=0.5, verbose=0, warm_start=False)\n",
      "Fold #0: loss=0.4793195080986177\n",
      "Fold #1: loss=0.45475240723521165\n",
      "Fold #2: loss=0.4813211482585229\n",
      "Fold #3: loss=0.4424828062375786\n",
      "Fold #4: loss=0.5026733574954969\n",
      "Fold #5: loss=0.49892070926899174\n",
      "Fold #6: loss=0.4450851677904585\n",
      "Fold #7: loss=0.4613043534912852\n",
      "Fold #8: loss=0.4616912272919031\n",
      "Fold #9: loss=0.47357839432294857\n",
      "GradientBoostingClassifier: Mean loss=0.47011290794910143\n",
      "\n",
      "Blending models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow.contrib.learn as learn\n",
    "import tensorflow as tf\n",
    "\n",
    "PATH = \"./data/\"\n",
    "SHUFFLE = False\n",
    "FOLDS = 10\n",
    "\n",
    "def mlogloss(y_test, preds):\n",
    "    epsilon = 1e-15\n",
    "    sum = 0\n",
    "    for row in zip(preds,y_test):\n",
    "        x = row[0][row[1]]\n",
    "        x = max(epsilon,x)\n",
    "        x = min(1-epsilon,x)\n",
    "        sum+=math.log(x)\n",
    "    return( (-1/len(preds))*sum)\n",
    "\n",
    "def stretch(y):\n",
    "    return (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "\n",
    "def blend_ensemble(x, y, x_submit):\n",
    "\n",
    "    folds = list(StratifiedKFold(y, FOLDS))\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[1])]\n",
    "\n",
    "    models = [\n",
    "        learn.DNNClassifier(hidden_units=[100, 50, 25, 5], n_classes=2, feature_columns=feature_columns),\n",
    "        KNeighborsClassifier(n_neighbors=3),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "        ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "        ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)]\n",
    "\n",
    "    dataset_blend_train = np.zeros((x.shape[0], len(models)))\n",
    "    dataset_blend_test = np.zeros((x_submit.shape[0], len(models)))\n",
    "\n",
    "    for j, model in enumerate(models):\n",
    "        print(\"Model: {} : {}\".format(j, model) )\n",
    "        fold_sums = np.zeros((x_submit.shape[0], len(folds)))\n",
    "        total_loss = 0\n",
    "        for i, (train, test) in enumerate(folds):\n",
    "            x_train = x[train]\n",
    "            y_train = y[train]\n",
    "            x_test = x[test]\n",
    "            y_test = y[test]\n",
    "            \n",
    "            if type(model) == tf.contrib.learn.python.learn.estimators.dnn.DNNClassifier:\n",
    "                model.fit(x_train, y_train,steps=10)\n",
    "                pred = np.array(list(classifier.predict_proba(x_test, as_iterable=True)))\n",
    "                pred2 = np.array(list(classifier.predict_proba(x_submit, as_iterable=True)))\n",
    "            else:\n",
    "                model.fit(x_train, y_train)\n",
    "                pred = model.predict_proba(x_test)\n",
    "                pred2 = model.predict_proba(x_submit)\n",
    "                \n",
    "            dataset_blend_train[test, j] = pred[:, 1]\n",
    "            fold_sums[:, i] = pred2[:, 1]\n",
    "            \n",
    "            loss = mlogloss(y_test, pred)\n",
    "            total_loss+=loss\n",
    "            print(\"Fold #{}: loss={}\".format(i,loss))\n",
    "        print(\"{}: Mean loss={}\".format(model.__class__.__name__,total_loss/len(folds)))\n",
    "        dataset_blend_test[:, j] = fold_sums.mean(1)\n",
    "\n",
    "    print()\n",
    "    print(\"Blending models.\")\n",
    "    blend = LogisticRegression()\n",
    "    blend.fit(dataset_blend_train, y)\n",
    "    return blend.predict_proba(dataset_blend_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(42)  # seed to shuffle the train set\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    filename_train = os.path.join(PATH, \"bio_train.csv\")\n",
    "    df_train = pd.read_csv(filename_train, na_values=['NA', '?'])\n",
    "\n",
    "    filename_submit = os.path.join(PATH, \"bio_test.csv\")\n",
    "    df_submit = pd.read_csv(filename_submit, na_values=['NA', '?'])\n",
    "\n",
    "    predictors = list(df_train.columns.values)\n",
    "    predictors.remove('Activity')\n",
    "    x = df_train.as_matrix(predictors)\n",
    "    y = df_train['Activity']\n",
    "    x_submit = df_submit.as_matrix()\n",
    "\n",
    "    if SHUFFLE:\n",
    "        idx = np.random.permutation(y.size)\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "    submit_data = blend_ensemble(x, y, x_submit)\n",
    "    submit_data = stretch(submit_data)\n",
    "\n",
    "    ####################\n",
    "    # Build submit file\n",
    "    ####################\n",
    "    ids = [id+1 for id in range(submit_data.shape[0])]\n",
    "    submit_filename = os.path.join(PATH, \"bio_submit.csv\")\n",
    "    submit_df = pd.DataFrame({'MoleculeId': ids, 'PredictedProbability': submit_data[:, 1]},\n",
    "                             columns=['MoleculeId','PredictedProbability'])\n",
    "    submit_df.to_csv(submit_filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
